{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Heart Disease Predictions",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "data855_heart_disease_path = kagglehub.dataset_download('data855/heart-disease')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "bDo7DPuMS-v1"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"text-align: left; background-color:#4e4e4e; font-family: Trebuchet MS; color:white; padding: 12px; line-height:1.25;border-radius:1px; margin-bottom: 0em; text-align: center; font-size: 38px;border-style: solid;border-color: dark green;\">Heart Diseases: What are the indicators?</div>\n",
        "\n",
        "<br> </br>\n",
        "<div>    \n",
        "\n",
        "<img src=\"https://images2.minutemediacdn.com/image/upload/c_fill,w_1080,ar_16:9,f_auto,q_auto,g_auto/shape%2Fcover%2Fsport%2F535618-istock-819924240-2470f65174198a2b48b33619995f99ad.jpg\" width=\"550/\">    \n",
        "</div>\n",
        "\n",
        "<div style=\"text-align: left; background-color:#4e4e4e; font-family: Trebuchet MS; color:white; padding: 12px; line-height:1.25;border-radius:1px; margin-bottom: 0em; text-align: center; font-size: 12px;border-style: solid;border-color: dark green;\"><p><b><a href=\"https://www.mentalfloss.com/article/535618/super-ekg-could-diagnose-heart-disease-90-seconds\" target=\"\">Image source</a></b></p></div>\n",
        "\n",
        "\n",
        "# 0. **Introduction** <a class=\"anchor\" id=\"0\"></a>\n",
        "\"Heart disease, also referred as cardiovascular diseases, is broad term used for diseases and conditions affecting the heart and circulatory system. It is a major cause of disability all around the world. Since heart is amongst the most vital organs of the body, its diseases affect other organs and part of the body as well. There are several different types and forms of heart diseases. The most common ones cause narrowing or blockage of the coronary arteries, malfunctioning in the valves of the heart, enlargement in the size of heart and several others leading to **heart failure** and **heart attack**.\" [[Source](https://www.indushealthplus.com/heart-diseases.html)]\n",
        "\n",
        "<blockquote style=\"margin-right:auto; margin-left:auto; color:white; background-color:#4e4e4e; padding: 1em; margin:24px;\">\n",
        "\n",
        "<font color=\"white\" size=+1.0><b>Key facts according to WHO (World Health Organaizations)</b></font>  \n",
        "        \n",
        "<ul>\n",
        "<li> Cardiovascular diseases (CVDs) are the leading cause of death globally.\n",
        "<li> An estimated 17.9 million people died from CVDs in 2019, representing 32% of all global deaths. Of these deaths, 85% were due to heart attack and stroke.\n",
        "<li> Over three quarters of CVD deaths take place in low- and middle-income countries.\n",
        "<li> Out of the 17 million premature deaths (under the age of 70) due to noncommunicable diseases in 2019, 38% were caused by CVDs.\n",
        "<li> Most cardiovascular diseases can be prevented by addressing behavioural risk factors such as tobacco use, unhealthy diet and obesity, physical inactivity and harmful use of alcohol.\n",
        "<li> It is important to detect cardiovascular disease as early as possible so that management with counselling and medicines can begin.                                                                                                                                 \n",
        "    \n",
        "</ul>        \n",
        "</blockquote>\n",
        "\n",
        "#### **Objectives**\n",
        "This notebook has two main objectives:\n",
        "* Explore the heart disease dataset using exploratory data analysis (EDA)\n",
        "* Exercise with classification algorithms for prediction (modelling)\n",
        "---\n",
        "\n",
        "<a id=\"top\"></a>\n",
        "\n",
        "## **Table of Contents**\n",
        "\n",
        "* [0. Introduction](#0)\n",
        "* [1. Exploratory Data Analysis](#1)\n",
        "    * [1.1 Data Dictionary](#1.1)\n",
        "    * [1.2 Data Pre-processing](#1.2)\n",
        "    * [1.3 Exploring Features](#1.3)\n",
        "    * [1.4 Correlations Heatmap](#1.4)\n",
        "    * [1.5 EDA Summary](#1.5)\n",
        "* [2. Predictions](#2)\n",
        "    * [2.1 Scikit Learn Classifiers](#2.1)\n",
        "    * [2.2 Catboost, Lgbm and Xgboost](#2.2)\n",
        "    * [2.3 Model Explainablity](#2.3)\n",
        "* [3. Concluding Remarks](#3)\n",
        "* [4. Reference](#4)\n"
      ],
      "metadata": {
        "id": "xFtPg4l2S-v5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 1. **Exploratory Data Analysis** <a class=\"anchor\" id=\"1\"></a>\n",
        "---"
      ],
      "metadata": {
        "id": "WlT2lXHES-v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from IPython.core.display import HTML\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import uniform\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:45.80559Z",
          "iopub.execute_input": "2023-04-30T16:23:45.806024Z",
          "iopub.status.idle": "2023-04-30T16:23:46.742629Z",
          "shell.execute_reply.started": "2023-04-30T16:23:45.805926Z",
          "shell.execute_reply": "2023-04-30T16:23:46.74136Z"
        },
        "trusted": true,
        "id": "jXIjW9PES-v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/kaggle/input/heart-disease/heart.csv')\n",
        "print('Shape of the data is ', data.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:46.744581Z",
          "iopub.execute_input": "2023-04-30T16:23:46.745Z",
          "iopub.status.idle": "2023-04-30T16:23:46.765175Z",
          "shell.execute_reply.started": "2023-04-30T16:23:46.744954Z",
          "shell.execute_reply": "2023-04-30T16:23:46.764205Z"
        },
        "trusted": true,
        "id": "6BbUNGjCS-v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:46.766783Z",
          "iopub.execute_input": "2023-04-30T16:23:46.767101Z",
          "iopub.status.idle": "2023-04-30T16:23:46.795368Z",
          "shell.execute_reply.started": "2023-04-30T16:23:46.767062Z",
          "shell.execute_reply": "2023-04-30T16:23:46.794359Z"
        },
        "trusted": true,
        "id": "0zfiCuPeS-v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:46.796919Z",
          "iopub.execute_input": "2023-04-30T16:23:46.797241Z",
          "iopub.status.idle": "2023-04-30T16:23:46.805636Z",
          "shell.execute_reply.started": "2023-04-30T16:23:46.797208Z",
          "shell.execute_reply": "2023-04-30T16:23:46.804748Z"
        },
        "trusted": true,
        "id": "JL2NqDyxS-v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: From the data types we see that all features are `int64/float64`. But that is because some of the categorical features including the target (has disease/no disease) are already label encoded for us. We will, in the section below, see a detailed decreption of the features."
      ],
      "metadata": {
        "id": "DX9sSoFeS-wA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1.1 **Data Dictionary** <a class=\"anchor\" id=\"1.1\"></a>\n",
        "\n",
        "1. age: age in years\n",
        "2. sex: sex\n",
        "    * 1 = male\n",
        "    * 0 = female\n",
        "3. cp: chest pain type\n",
        "    * Value 0: typical angina\n",
        "    * Value 1: atypical angina\n",
        "    * Value 2: non-anginal pain\n",
        "    * Value 3: asymptomatic\n",
        "4. trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
        "5. chol: serum cholestoral in mg/dl\n",
        "6. fbs: (fasting blood sugar > 120 mg/dl)\n",
        "    * 1 = true;\n",
        "    * 0 = false\n",
        "7. restecg: resting electrocardiographic results\n",
        "    * Value 0: normal\n",
        "    * Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
        "    * Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
        "8. thalach: maximum heart rate achieved\n",
        "9. exang: exercise induced angina\n",
        "    * 1 = yes\n",
        "    * 0 = no\n",
        "10. oldpeak = ST depression induced by exercise relative to rest\n",
        "11. slope: the slope of the peak exercise ST segment\n",
        "    * Value 0: upsloping\n",
        "    * Value 1: flat\n",
        "    * Value 2: downsloping\n",
        "12. ca: number of major vessels (0-3) colored by flourosopy\n",
        "13. thal:\n",
        "    * 0 = `error (in the original dataset 0 maps to NaN's)`\n",
        "    * 1 = fixed defect\n",
        "    * 2 = normal\n",
        "    * 3 = reversable defect\n",
        "14. target (the lable):\n",
        "    * 0 = no disease,\n",
        "    * 1 = disease\n",
        "---    \n",
        "**Note on the target label**:\n",
        "\n",
        "`Diagnosis of heart disease (angiographic disease status)\n",
        "Value 0: < 50% diameter narrowing\n",
        "Value 1: > 50% diameter narrowing`\n",
        "    \n",
        "**Notes from the discussion forum of the dataset**:\n",
        "\n",
        "* data #93, 159, 164, 165 and 252 have `ca=4` which is incorrect. In the original Cleveland dataset they are NaNs.\n",
        "* data #49 and 282 have `thal = 0`, also incorrect. They are also NaNs in the original dataset.\n",
        "\n",
        "**Action**:  Drop the faulty data! (7 data entry will be dropped)\n",
        "\n",
        "---\n",
        "\n",
        "<a href=\"#top\">☝️ Back to top</a>"
      ],
      "metadata": {
        "id": "wy9Efa_wS-wA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 **Data pre-processing** <a class=\"anchor\" id=\"1.2\"></a>\n",
        "### 1.2.1 Drop faulty data\n",
        "Based on our investigation we did above, we will drop 7 rows."
      ],
      "metadata": {
        "id": "yqTGR_PbS-wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data['ca'] < 4] #drop the wrong ca values\n",
        "data = data[data['thal'] > 0] # drop the wong thal value\n",
        "print(f'The length of the data now is {len(data)} instead of 303!')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:46.80679Z",
          "iopub.execute_input": "2023-04-30T16:23:46.807131Z",
          "iopub.status.idle": "2023-04-30T16:23:46.830574Z",
          "shell.execute_reply.started": "2023-04-30T16:23:46.807101Z",
          "shell.execute_reply": "2023-04-30T16:23:46.829485Z"
        },
        "trusted": true,
        "id": "9C1vCjvtS-wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Rename columns for the sake of clarity\n",
        "* The feature names in the dataset are abbreviated and hard to understand their meaning. A full medical/technical name is hard enough to understand for most of us let alone their short form. So to make them a little bit easier to read we will, here under, change the column names of the data frame using information from the UCL data repository.\n",
        "* We'll also replace the coded categories (0, 1, 2,..) to their medical meaning ('atypical angina', 'typical angina', etc. for example)\n",
        "* **Note**: I borrowed [Rob Harrand's](https://www.kaggle.com/tentotheminus9/what-causes-heart-disease-explaining-the-model) idea of re-naming the columns."
      ],
      "metadata": {
        "id": "mT_3xdOrS-wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.rename(\n",
        "    columns = {'cp':'chest_pain_type',\n",
        "               'trestbps':'resting_blood_pressure',\n",
        "               'chol': 'cholesterol',\n",
        "               'fbs': 'fasting_blood_sugar',\n",
        "               'restecg' : 'resting_electrocardiogram',\n",
        "               'thalach': 'max_heart_rate_achieved',\n",
        "               'exang': 'exercise_induced_angina',\n",
        "               'oldpeak': 'st_depression',\n",
        "               'slope': 'st_slope',\n",
        "               'ca':'num_major_vessels',\n",
        "               'thal': 'thalassemia'},\n",
        "    errors=\"raise\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:46.831903Z",
          "iopub.execute_input": "2023-04-30T16:23:46.832509Z",
          "iopub.status.idle": "2023-04-30T16:23:46.839047Z",
          "shell.execute_reply.started": "2023-04-30T16:23:46.832465Z",
          "shell.execute_reply": "2023-04-30T16:23:46.838142Z"
        },
        "trusted": true,
        "id": "N3QCTKnDS-wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['sex'][data['sex'] == 0] = 'female'\n",
        "data['sex'][data['sex'] == 1] = 'male'\n",
        "\n",
        "data['chest_pain_type'][data['chest_pain_type'] == 0] = 'typical angina'\n",
        "data['chest_pain_type'][data['chest_pain_type'] == 1] = 'atypical angina'\n",
        "data['chest_pain_type'][data['chest_pain_type'] == 2] = 'non-anginal pain'\n",
        "data['chest_pain_type'][data['chest_pain_type'] == 3] = 'asymptomatic'\n",
        "\n",
        "data['fasting_blood_sugar'][data['fasting_blood_sugar'] == 0] = 'lower than 120mg/ml'\n",
        "data['fasting_blood_sugar'][data['fasting_blood_sugar'] == 1] = 'greater than 120mg/ml'\n",
        "\n",
        "data['resting_electrocardiogram'][data['resting_electrocardiogram'] == 0] = 'normal'\n",
        "data['resting_electrocardiogram'][data['resting_electrocardiogram'] == 1] = 'ST-T wave abnormality'\n",
        "data['resting_electrocardiogram'][data['resting_electrocardiogram'] == 2] = 'left ventricular hypertrophy'\n",
        "\n",
        "data['exercise_induced_angina'][data['exercise_induced_angina'] == 0] = 'no'\n",
        "data['exercise_induced_angina'][data['exercise_induced_angina'] == 1] = 'yes'\n",
        "\n",
        "data['st_slope'][data['st_slope'] == 0] = 'upsloping'\n",
        "data['st_slope'][data['st_slope'] == 1] = 'flat'\n",
        "data['st_slope'][data['st_slope'] == 2] = 'downsloping'\n",
        "\n",
        "data['thalassemia'][data['thalassemia'] == 1] = 'fixed defect'\n",
        "data['thalassemia'][data['thalassemia'] == 2] = 'normal'\n",
        "data['thalassemia'][data['thalassemia'] == 3] = 'reversable defect'"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:46.84047Z",
          "iopub.execute_input": "2023-04-30T16:23:46.840866Z",
          "iopub.status.idle": "2023-04-30T16:23:46.897638Z",
          "shell.execute_reply.started": "2023-04-30T16:23:46.840815Z",
          "shell.execute_reply": "2023-04-30T16:23:46.896794Z"
        },
        "trusted": true,
        "id": "prxWgA8SS-wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:46.899912Z",
          "iopub.execute_input": "2023-04-30T16:23:46.900211Z",
          "iopub.status.idle": "2023-04-30T16:23:46.907579Z",
          "shell.execute_reply.started": "2023-04-30T16:23:46.900168Z",
          "shell.execute_reply": "2023-04-30T16:23:46.906505Z"
        },
        "trusted": true,
        "id": "PhQvpfCsS-wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:46.909596Z",
          "iopub.execute_input": "2023-04-30T16:23:46.909906Z",
          "iopub.status.idle": "2023-04-30T16:23:46.932473Z",
          "shell.execute_reply.started": "2023-04-30T16:23:46.90987Z",
          "shell.execute_reply": "2023-04-30T16:23:46.931428Z"
        },
        "trusted": true,
        "id": "JIKOAEzKS-wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.3 Grouping Features (by data type)\n",
        "* As we have seen above there are three datatypes i.e **object**, **int** and **floats**. Let's group them according to type.\n"
      ],
      "metadata": {
        "id": "rm1SquDVS-wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numerical fearures 6\n",
        "num_feats = ['age', 'cholesterol', 'resting_blood_pressure', 'max_heart_rate_achieved', 'st_depression', 'num_major_vessels']\n",
        "# categorical (binary)\n",
        "bin_feats = ['sex', 'fasting_blood_sugar', 'exercise_induced_angina', 'target']\n",
        "# caterorical (multi-)\n",
        "nom_feats= ['chest_pain_type', 'resting_electrocardiogram', 'st_slope', 'thalassemia']\n",
        "cat_feats = nom_feats + bin_feats"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:46.933996Z",
          "iopub.execute_input": "2023-04-30T16:23:46.934334Z",
          "iopub.status.idle": "2023-04-30T16:23:46.940681Z",
          "shell.execute_reply.started": "2023-04-30T16:23:46.934293Z",
          "shell.execute_reply": "2023-04-30T16:23:46.93966Z"
        },
        "trusted": true,
        "id": "8nKJE6yoS-wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 **Exploring Features/Target** <a class=\"anchor\" id=\"1.3\"></a>\n",
        "\n",
        "In this section we'll investigate all the features (including the target) in detail. We will look at the statistical summary when possible and the distributions of some of them as well, starting from the target.\n",
        "\n",
        "### 1.3.1 Target distribution\n",
        "\n",
        "We observe that the target is fairly balanced with ~46% with no heart disease and ~54% with heart disease. So no need to worry about target imbalance.\n"
      ],
      "metadata": {
        "id": "AIp11GbIS-wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mypal= ['#FC05FB', '#FEAEFE', '#FCD2FC','#F3FEFA', '#B4FFE4','#3FFEBA']\n",
        "\n",
        "plt.figure(figsize=(7, 5),facecolor='#F6F5F4')\n",
        "total = float(len(data))\n",
        "ax = sns.countplot(x=data['target'], palette=mypal[1::4])\n",
        "ax.set_facecolor('#F6F5F4')\n",
        "\n",
        "for p in ax.patches:\n",
        "\n",
        "    height = p.get_height()\n",
        "    ax.text(p.get_x()+p.get_width()/2.,height + 3,'{:1.1f} %'.format((height/total)*100), ha=\"center\",\n",
        "           bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.5))\n",
        "\n",
        "ax.set_title('Target variable distribution', fontsize=20, y=1.05)\n",
        "sns.despine(right=True)\n",
        "sns.despine(offset=5, trim=True)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:46.942113Z",
          "iopub.execute_input": "2023-04-30T16:23:46.942498Z",
          "iopub.status.idle": "2023-04-30T16:23:47.14135Z",
          "shell.execute_reply.started": "2023-04-30T16:23:46.942466Z",
          "shell.execute_reply": "2023-04-30T16:23:47.14032Z"
        },
        "trusted": true,
        "id": "_T_Afp-rS-wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.2 Numerical Features\n",
        "\n",
        "#### Statistical summary\n",
        "\n",
        "For the numerical features we can apply the handy pandas `data.describe()` method and get the global statistical summary. Key figures are highlighted below."
      ],
      "metadata": {
        "id": "KDlcQorXS-wI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[num_feats].describe().T"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:47.142887Z",
          "iopub.execute_input": "2023-04-30T16:23:47.143522Z",
          "iopub.status.idle": "2023-04-30T16:23:47.181377Z",
          "shell.execute_reply.started": "2023-04-30T16:23:47.143477Z",
          "shell.execute_reply": "2023-04-30T16:23:47.180334Z"
        },
        "trusted": true,
        "id": "O0twyESWS-wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Statistical summary of the numerical features**\n",
        "\n",
        "<blockquote style=\"margin-right:auto; margin-left:auto; color:white; background-color: #4e4e4e; padding: 1em; margin:24px;\">\n",
        "   \n",
        "<ul>\n",
        "<li> <font color=\"white\" size=+1.0><b>Age</b></font> :\n",
        "    <ul>\n",
        "    <li> The average age in the dataset is 54.5 years\n",
        "    <li> The oldest is 77 years, whereas the youngest is 29 years old\n",
        "    </ul>\n",
        "<li> <font color=\"white\" size=+1.0><b>Cholesterol:</b></font>\n",
        "    <ul>\n",
        "    <li> The average registered cholestrol level is 247.15\n",
        "    <li> Maximum level is 564 and the minimum level is 126.\n",
        "    <li> <strong>Note</strong>: According to [6], a healthy cholesterol level is $<200 mg/dl$ and usually high level of cholesterol is associated with heart disease.\n",
        "    </ul>\n",
        "<li> <font color=\"white\" size=+1.0><b>Resting blood pressure:</b></font>\n",
        "    <ul>\n",
        "    <li> 131 mean, 200 max and 94 min\n",
        "    </ul>\n",
        "<li> <font color=\"white\" size=+1.0><b>Max heart rate achieved:</b></font>\n",
        "    <ul>\n",
        "    <li> The abverage max heart rate registered is 149.5 bpm. The Maximum and the minumum are 202 and 71bpm respectively.\n",
        "    </ul>\n",
        "<li> <font color=\"white\" size=+1.0><b>St_depression:</b></font>\n",
        "    <ul>\n",
        "    <li> The average value of st_dpression is 1.06. Max is 6.2 and the minimum is 0.\n",
        "    </ul>\n",
        "<li> <font color=\"white\" size=+1.0><b>Number of major blood vessels:</b></font>\n",
        "    <ul>\n",
        "    <li> A maximum of 3 and a minimum of 0 major blood vessels are observed. The mean value is 0.68.\n",
        "    </ul>\n",
        "</ul>                                                                                                                                             \n",
        "</blockquote>\n",
        "\n",
        "<a href=\"#top\">☝️ Back to top</a>                                                                                                                                                   "
      ],
      "metadata": {
        "id": "-jxT8ihIS-wI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribution: Density plots"
      ],
      "metadata": {
        "id": "7rGdCrWSS-wJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L = len(num_feats)\n",
        "ncol= 2\n",
        "nrow= int(np.ceil(L/ncol))\n",
        "#remove_last= (nrow * ncol) - L\n",
        "\n",
        "fig, ax = plt.subplots(nrow, ncol, figsize=(16, 14),facecolor='#F6F5F4')\n",
        "fig.subplots_adjust(top=0.92)\n",
        "\n",
        "i = 1\n",
        "for col in num_feats:\n",
        "    plt.subplot(nrow, ncol, i, facecolor='#F6F5F4')\n",
        "\n",
        "    ax = sns.kdeplot(data=data, x=col, hue=\"target\", multiple=\"stack\", palette=mypal[1::4])\n",
        "    ax.set_xlabel(col, fontsize=20)\n",
        "    ax.set_ylabel(\"density\", fontsize=20)\n",
        "    sns.despine(right=True)\n",
        "    sns.despine(offset=0, trim=False)\n",
        "\n",
        "    if col == 'num_major_vessels':\n",
        "        sns.countplot(data=data, x=col, hue=\"target\", palette=mypal[1::4])\n",
        "        for p in ax.patches:\n",
        "                height = p.get_height()\n",
        "                ax.text(p.get_x()+p.get_width()/2.,height + 3,'{:1.0f}'.format((height)),ha=\"center\",\n",
        "                      bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.5))\n",
        "\n",
        "    i = i +1\n",
        "plt.suptitle('Distribution of Numerical Features' ,fontsize = 24);"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:47.182877Z",
          "iopub.execute_input": "2023-04-30T16:23:47.183472Z",
          "iopub.status.idle": "2023-04-30T16:23:49.448846Z",
          "shell.execute_reply.started": "2023-04-30T16:23:47.183427Z",
          "shell.execute_reply": "2023-04-30T16:23:49.448069Z"
        },
        "trusted": true,
        "id": "sF0KYV9IS-wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pair-plots"
      ],
      "metadata": {
        "id": "DCeb-yERS-wJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = ['age', 'cholesterol', 'resting_blood_pressure', 'max_heart_rate_achieved', 'st_depression', 'target']\n",
        "data_ = data[_]\n",
        "g = sns.pairplot(data_, hue=\"target\", corner=True, diag_kind='hist', palette=mypal[1::4]);\n",
        "plt.suptitle('Pairplot: Numerical Features ' ,fontsize = 24);"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:49.449938Z",
          "iopub.execute_input": "2023-04-30T16:23:49.450423Z",
          "iopub.status.idle": "2023-04-30T16:23:54.4547Z",
          "shell.execute_reply.started": "2023-04-30T16:23:49.45038Z",
          "shell.execute_reply": "2023-04-30T16:23:54.453518Z"
        },
        "trusted": true,
        "id": "LcJXYCuHS-wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Selected Features\n",
        "\n",
        "Below are reg-plots of some selected features showing the linear relation with Age, similar to the first column in the pair-plot above. We observe that:\n",
        "- Except `maximum_heart_rate_achieved`, the others are positively and linearly related with `age` (albeit a weaker relation with `st_depression`).\n",
        "- Younger patients with higher `maximum_heart_rate_achieved` are more likely to have a heart condition.\n",
        "- Lower `st_depression` regardless of age is also likely an indication of a heart disease.\n"
      ],
      "metadata": {
        "id": "JMX2li-mS-wK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,4, figsize=(20, 4))\n",
        "sns.regplot(data=data[data['target'] ==1], x='age', y='cholesterol', ax = ax[0], color=mypal[0], label='1')\n",
        "sns.regplot(data=data[data['target'] ==0], x='age', y='cholesterol', ax = ax[0], color=mypal[5], label='0')\n",
        "sns.regplot(data=data[data['target'] ==1], x='age', y='max_heart_rate_achieved', ax = ax[1], color=mypal[0], label='1')\n",
        "sns.regplot(data=data[data['target'] ==0], x='age', y='max_heart_rate_achieved', ax = ax[1], color=mypal[5], label='0')\n",
        "sns.regplot(data=data[data['target'] ==1], x='age', y='resting_blood_pressure', ax = ax[2], color=mypal[0], label='1')\n",
        "sns.regplot(data=data[data['target'] ==0], x='age', y='resting_blood_pressure', ax = ax[2], color=mypal[5], label='0')\n",
        "sns.regplot(data=data[data['target'] ==1], x='age', y='st_depression', ax = ax[3], color=mypal[0], label='1')\n",
        "sns.regplot(data=data[data['target'] ==0], x='age', y='st_depression', ax = ax[3], color=mypal[5], label='0')\n",
        "plt.suptitle('Reg plots of selected features')\n",
        "plt.legend();"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:54.456261Z",
          "iopub.execute_input": "2023-04-30T16:23:54.45692Z",
          "iopub.status.idle": "2023-04-30T16:23:56.036187Z",
          "shell.execute_reply.started": "2023-04-30T16:23:54.456874Z",
          "shell.execute_reply": "2023-04-30T16:23:56.035429Z"
        },
        "trusted": true,
        "id": "jaHiABg_S-wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1.3.3 Categorical Features\n",
        "\n",
        "                                                                                                                                    \n",
        "We use a count plot to visualize the different categories with respect to the target variable. Two things we could take note of are the distribution of each category in the dataset and their contribution to the probability of correct prediction of the target variable, i.e has disease (=1) or has no disease (=0). Below is the summary of the categorical features.\n",
        "\n",
        "<blockquote style=\"margin-right:auto; margin-left:auto; color:white; background-color: #4e4e4e; padding: 1em; margin:24px;\">\n",
        "   \n",
        "<ul>\n",
        "<li> <font color=\"white\" size=+1.0><b>Chest Pain:</b></font>\n",
        "    <ul>\n",
        "        <li> More than 75% of the patients experience either <strong><em>typical angina</em></strong> or <strong><em>non-angina</em></strong> chest pain.\n",
        "        <li> Patients who experienced <em>atypical angina</em> or <strong>non-angina</strong> chest pain are more likely to have a heart disease.\n",
        "    </ul>  \n",
        "    \n",
        "<li> <font color=\"white\" size=+1.0><b>Resting Electrocardiogram:</b></font>\n",
        "    <ul>\n",
        "        <li> Patients with <strong>Left ventricular hypertrophy</strong> are the fewest (~1.4%). The rest is almost a 50-50 split between patients with <strong>ST-T abnormality</strong> and those with normal REC tests.\n",
        "        <li> <strong>ST-T abnormality</strong>  seem to have a better correlation with the target, i.e the majority of patients with this kind of REC test ended up with a heart disease.\n",
        "</ul>    \n",
        "<li> <font color=\"white\" size=+1.0><b>ST-Slope:</b></font>\n",
        "    <ul>\n",
        "    <li> Most patients have a <strong>downsloping</strong> or <strong>flat</strong> ST-Slope of their REC test.\n",
        "    <li> <strong>downsloping</strong> ST-Slopes are a strong indication that a patient might have a heart disease.\n",
        "</ul>   \n",
        "    \n",
        "<li> <font color=\"white\" size=+1.0><b>Thalassemia:</b></font>\n",
        "    <ul>\n",
        "    <li> Most patients have a <strong>normal</strong> or <strong>reversable defect</strong>\n",
        "    <li> Patients who have thalassemia defects (reversable + fixed) are less likely to have a heart disease. Whereas, those with normal thalassemia are more likely to have a heart condition. Sounds not intuitive.\n",
        "</ul>   \n",
        "    \n",
        "<li> <font color=\"white\" size=+1.0><b>Fasting blood sugar</b></font>\n",
        "    <ul>\n",
        "    <li> Patients with lower (less than 120mg/ml) <strong>fasting blood sugar</strong> are the majority in our dataset consisting of ~85% of the sample.\n",
        "    <li> Having lower resting blood sugar tends to increase the chances (~54%) of a heart disease.\n",
        "</ul>   \n",
        "    \n",
        "<li> <font color=\"white\" size=+1.0><b>Exercise Induced Angina</b></font>\n",
        "    <ul>\n",
        "    <li> Two-third of the patients showed no exercise induced angina.\n",
        "    <li> 76% of the patients with exercise induced angina had no heart conditions. Whereas ~69% of the patients who did not experience exercise induced angina were diagnosed with heart condition.\n",
        "</ul>\n",
        "    \n",
        "<li> <font color=\"white\" size=+1.0><b>Sex</b></font>\n",
        "    <ul>\n",
        "    <li> More patients in the sample data are male.\n",
        "    <li> Females seem to suffer from heart condition more than males.\n",
        "</ul>   \n",
        "    \n",
        "</ul>                                                                                                                                             \n",
        "</blockquote>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J3mTTa74S-wK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- def cat_freq_counter(df, columns):\n",
        "    dataFrames_ = []\n",
        "    for col in columns:\n",
        "        dataFrames_.append(pd.DataFrame(df[col].value_counts()).style.background_gradient(cmap='cool'))\n",
        "    return HTML(f\"<table><tr> {''.join(['<td>' + dfs._repr_html_() + '</td>' for dfs in dataFrames_])} </tr></table>\")\n",
        "\n",
        "# split the width of the output\n",
        "display(cat_freq_counter(data, cat_feats[0:4]))\n",
        "display(cat_freq_counter(data, cat_feats[4:])) -->"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-14T21:05:09.789516Z",
          "iopub.execute_input": "2022-06-14T21:05:09.790033Z",
          "iopub.status.idle": "2022-06-14T21:05:09.859343Z",
          "shell.execute_reply.started": "2022-06-14T21:05:09.79Z",
          "shell.execute_reply": "2022-06-14T21:05:09.858201Z"
        },
        "_kg_hide-input": true,
        "id": "tAwY1Q9GS-wK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribution: Count plots"
      ],
      "metadata": {
        "id": "FXEFKnRMS-wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_plot(data, cat_feats):\n",
        "    L = len(cat_feats)\n",
        "    ncol= 2\n",
        "    nrow= int(np.ceil(L/ncol))\n",
        "    remove_last= (nrow * ncol) - L\n",
        "\n",
        "    fig, ax = plt.subplots(nrow, ncol,figsize=(18, 24), facecolor='#F6F5F4')\n",
        "    fig.subplots_adjust(top=0.92)\n",
        "    ax.flat[-remove_last].set_visible(False)\n",
        "\n",
        "    i = 1\n",
        "    for col in cat_feats:\n",
        "        plt.subplot(nrow, ncol, i, facecolor='#F6F5F4')\n",
        "        ax = sns.countplot(data=data, x=col, hue=\"target\", palette=mypal[1::4])\n",
        "        ax.set_xlabel(col, fontsize=20)\n",
        "        ax.set_ylabel(\"count\", fontsize=20)\n",
        "        sns.despine(right=True)\n",
        "        sns.despine(offset=0, trim=False)\n",
        "        plt.legend(facecolor='#F6F5F4')\n",
        "\n",
        "        for p in ax.patches:\n",
        "            height = p.get_height()\n",
        "            ax.text(p.get_x()+p.get_width()/2.,height + 3,'{:1.0f}'.format((height)),ha=\"center\",\n",
        "                  bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.5))\n",
        "\n",
        "        i = i +1\n",
        "\n",
        "    plt.suptitle('Distribution of Categorical Features' ,fontsize = 24)\n",
        "    return 0\n",
        "\n",
        "count_plot(data, cat_feats[0:-1]);"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:56.037393Z",
          "iopub.execute_input": "2023-04-30T16:23:56.03784Z",
          "iopub.status.idle": "2023-04-30T16:23:58.316915Z",
          "shell.execute_reply.started": "2023-04-30T16:23:56.037798Z",
          "shell.execute_reply": "2023-04-30T16:23:58.315695Z"
        },
        "trusted": true,
        "id": "TopkLG33S-wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1.4 **Correlation Heatmaps** <a class=\"anchor\" id=\"1.4\"></a>\n",
        "\n",
        "Correlation heatmap is a useful tool to graphyically represent how two features are related to eachother. Depending upon the data types of the features, we need to use the appropriate correlation coefficient calculation methods. Examples are pearson's correlation coefficient, point biserial correlation, cramers'V correlation and etc.\n",
        "\n",
        "### 1.4.1 Pearson's correlation\n",
        "\n",
        "* The Pearson correlation coefficient ― is a measure of linear correlation between two sets of data. It is the ratio between the covariance of two variables and the product of their standard deviations; thus it is essentially a normalised measurement of the covariance, such that the result always has a value between −1 and 1. ([ref. ](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient))"
      ],
      "metadata": {
        "id": "Mz3YVg5zS-wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ = data[num_feats]\n",
        "corr = df_.corr(method='pearson')\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "f, ax = plt.subplots(figsize=(8, 5), facecolor=None)\n",
        "cmap = sns.color_palette(mypal, as_cmap=True)\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1.0, vmin=-1.0, center=0, annot=True,\n",
        "            square=False, linewidths=.5, cbar_kws={\"shrink\": 0.75})\n",
        "ax.set_title(\"Numerical features correlation (Pearson's)\", fontsize=20, y= 1.05);"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:58.318438Z",
          "iopub.execute_input": "2023-04-30T16:23:58.318843Z",
          "iopub.status.idle": "2023-04-30T16:23:58.692112Z",
          "shell.execute_reply.started": "2023-04-30T16:23:58.318801Z",
          "shell.execute_reply": "2023-04-30T16:23:58.691333Z"
        },
        "trusted": true,
        "id": "6njzjPsFS-wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.2 Point biserial correlation\n",
        "- A point-biserial correlation is used to measure the strength and direction of the association that exists between **one continuous variable and one dichotomous variable**. It is a special case of the Pearson’s product-moment correlation, which is applied when you have two continuous variables, whereas in this case one of the variables is measured on a dichotomous scale [[ref. ](https://statistics.laerd.com/spss-tutorials/point-biserial-correlation-using-spss-statistics.php)]."
      ],
      "metadata": {
        "id": "_lvPNp4HS-wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feats_ = ['age', 'cholesterol', 'resting_blood_pressure', 'max_heart_rate_achieved', 'st_depression', 'num_major_vessels', 'target']\n",
        "\n",
        "def point_biserial(x, y):\n",
        "    pb = stats.pointbiserialr(x, y)\n",
        "    return pb[0]\n",
        "\n",
        "rows= []\n",
        "for x in feats_:\n",
        "    col = []\n",
        "    for y in feats_ :\n",
        "        pbs =point_biserial(data[x], data[y])\n",
        "        col.append(round(pbs,2))\n",
        "    rows.append(col)\n",
        "\n",
        "pbs_results = np.array(rows)\n",
        "DF = pd.DataFrame(pbs_results, columns = data[feats_].columns, index =data[feats_].columns)\n",
        "\n",
        "mask = np.triu(np.ones_like(DF, dtype=bool))\n",
        "corr = DF.mask(mask)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(8, 5), facecolor=None)\n",
        "cmap = sns.color_palette(mypal, as_cmap=True)\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1.0, vmin=-1, center=0, annot=True,\n",
        "            square=False, linewidths=.5, cbar_kws={\"shrink\": 0.75})\n",
        "ax.set_title(\"Cont feats vs target correlation (point-biserial)\", fontsize=20, y= 1.05);"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:58.693267Z",
          "iopub.execute_input": "2023-04-30T16:23:58.693683Z",
          "iopub.status.idle": "2023-04-30T16:23:59.112003Z",
          "shell.execute_reply.started": "2023-04-30T16:23:58.693652Z",
          "shell.execute_reply": "2023-04-30T16:23:59.111269Z"
        },
        "trusted": true,
        "id": "AMBMBXtgS-wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.3 Cramer's V correlation\n",
        "\n",
        "* In statistics, Cramér's V is a measure of association between **two nominal variables**, giving a value between 0 and +1 (inclusive). It is based on Pearson's chi-squared statistic and was published by Harald Cramér in 1946. [[ref. ](https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V)]"
      ],
      "metadata": {
        "id": "iqEYlrQNS-wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the cramers_v function is copied from https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9\n",
        "\n",
        "def cramers_v(x, y):\n",
        "    confusion_matrix = pd.crosstab(x,y)\n",
        "    chi2 = stats.chi2_contingency(confusion_matrix)[0]\n",
        "    n = confusion_matrix.sum().sum()\n",
        "    phi2 = chi2/n\n",
        "    r,k = confusion_matrix.shape\n",
        "    phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n",
        "    rcorr = r-((r-1)**2)/(n-1)\n",
        "    kcorr = k-((k-1)**2)/(n-1)\n",
        "    return np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))\n",
        "\n",
        "# calculate the correlation coefficients using the above function\n",
        "data_ = data[cat_feats]\n",
        "rows= []\n",
        "for x in data_:\n",
        "    col = []\n",
        "    for y in data_ :\n",
        "        cramers =cramers_v(data_[x], data_[y])\n",
        "        col.append(round(cramers,2))\n",
        "    rows.append(col)\n",
        "\n",
        "cramers_results = np.array(rows)\n",
        "df = pd.DataFrame(cramers_results, columns = data_.columns, index = data_.columns)\n",
        "\n",
        "# color palette\n",
        "mypal_1= ['#FC05FB', '#FEAEFE', '#FCD2FC','#F3FEFA', '#B4FFE4','#3FFEBA', '#FC05FB', '#FEAEFE', '#FCD2FC']\n",
        "# plot the heat map\n",
        "mask = np.triu(np.ones_like(df, dtype=bool))\n",
        "corr = df.mask(mask)\n",
        "f, ax = plt.subplots(figsize=(10, 6), facecolor=None)\n",
        "cmap = sns.color_palette(mypal_1, as_cmap=True)\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1.0, vmin=0, center=0, annot=True,\n",
        "            square=False, linewidths=.01, cbar_kws={\"shrink\": 0.75})\n",
        "ax.set_title(\"Categorical Features Correlation (Cramer's V)\", fontsize=20, y= 1.05);"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:23:59.113149Z",
          "iopub.execute_input": "2023-04-30T16:23:59.113607Z",
          "iopub.status.idle": "2023-04-30T16:24:00.414385Z",
          "shell.execute_reply.started": "2023-04-30T16:23:59.113565Z",
          "shell.execute_reply": "2023-04-30T16:24:00.413331Z"
        },
        "trusted": true,
        "id": "QrhIhiSwS-wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"#top\">☝️ Back to top</a>"
      ],
      "metadata": {
        "id": "sIi78P4YS-wY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.5 EDA Summary**: <a class=\"anchor\" id=\"1.5\"></a>\n",
        "\n",
        "* Data size: 303 rows and 14 columns (13 independent + one target variable) > later reduced to 296 after removing faulty data points!\n",
        "* Data has no missing values\n",
        "* Features (columns) data type:\n",
        "    * Six features are numerical\n",
        "    * The rest (seven features) are categorical variables\n",
        "* Target variable is fairly balanced, 54% no-disease to 46% has-disease\n",
        "* Correlations:\n",
        "    * Correlation between features is weak at best\n",
        "    * From the numerical features `num_major_vessels`, `max_heart_rate_achieved` and `st_depression` are reasonabily fairly correlated with the target variable at -0.47, 0.43 and -0.43 correlation coefficient respectively.\n",
        "    * From the categorical features `chest_pain_type`, `num_major_vessels`, `thalassemia`, and `exercise_induced_angina` are better correlated with the target variable, `thalassemia` being the highest at 0.52.\n",
        "    * Cholestrol (to my surprize, but what do I know?) has less correlation with heart desease.\n",
        "    \n",
        "**Takeaway**: features that have higher predictive power could be, **`chest_pain_type`, `num_major_vessels`, `thalassemia`, `exercise_induced_angina` `max_heart_rate_achieved`** and **`st_depression`**. We will see which features will appear as imporatnt by the classification models.\n",
        "            "
      ],
      "metadata": {
        "id": "qKU2TR5nS-wZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 2. **Predictions** <a class=\"anchor\" id=\"2\"></a>\n",
        "---\n",
        "**Note** : We have only 297 case (after data cleaning) which is a very small amount of data to do any serious prediction. Therefore, any conclusion made must be taken with cautions. This notebook is merely an excercise on binary classification algorithms.\n",
        "\n",
        "## 2.1 **Scikit Learn Classifiers** <a class=\"anchor\" id=\"2.1\"></a>\n",
        "\n",
        "This is a binary classification problem (has-disease or no-disease cases). Scikit learn offers a wide range of classification algorithms and is often the starting point in most/traditional machine learning challenges, so we start by exploring few of the classification alorithms from the sklearn libarary such as `Logistic Regression`, `Nearest Neighbors`, `Support Vectors`, `Nu SVC`, `Decision Tree`, `Random Forest`, `AdaBoost`, `Gradient Boosting`, `Naive Bayes`, `Linear Discriminant Analysis`, `Quadratic Discriminant Analysis` and `Neural Net`. Let's first build simple models using the above mentioned ML algorithms and later we will optimize them by tuning the parameters."
      ],
      "metadata": {
        "id": "PbHKNw03S-wZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
        "from sklearn.metrics import recall_score, accuracy_score,roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import shap"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:00.415889Z",
          "iopub.execute_input": "2023-04-30T16:24:00.416499Z",
          "iopub.status.idle": "2023-04-30T16:24:08.790519Z",
          "shell.execute_reply.started": "2023-04-30T16:24:00.416456Z",
          "shell.execute_reply": "2023-04-30T16:24:08.789607Z"
        },
        "trusted": true,
        "id": "tGVtiUqSS-wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encode_cat_features(data, cat_features):\n",
        "    '''\n",
        "    Given a dataframe and its categorical features, this function returns label-encoded dataframe\n",
        "    '''\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    data_encoded = data.copy()\n",
        "\n",
        "    for col in cat_features:\n",
        "        data_encoded[col] = label_encoder.fit_transform(data[col])\n",
        "\n",
        "    data = data_encoded\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def score_summary(names, classifiers):\n",
        "    '''\n",
        "    Given a list of classiers, this function calculates the accuracy,\n",
        "    ROC_AUC and Recall and returns the values in a dataframe\n",
        "    '''\n",
        "\n",
        "    cols=[\"Classifier\", \"Accuracy\", \"ROC_AUC\", \"Recall\", \"Precision\", \"F1\"]\n",
        "    data_table = pd.DataFrame(columns=cols)\n",
        "\n",
        "    for name, clf in zip(names, classifiers):\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        pred = clf.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, pred)\n",
        "\n",
        "        pred_proba = clf.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        fpr, tpr, thresholds = roc_curve(y_val, pred_proba)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # confusion matric, cm\n",
        "        cm = confusion_matrix(y_val, pred)\n",
        "\n",
        "        # recall: TP/(TP+FN)\n",
        "        recall = cm[1,1]/(cm[1,1] +cm[1,0])\n",
        "\n",
        "        # precision: TP/(TP+FP)\n",
        "        precision = cm[1,1]/(cm[1,1] +cm[0,1])\n",
        "\n",
        "        # F1 score: TP/(TP+FP)\n",
        "        f1 = 2*recall*precision/(recall + precision)\n",
        "\n",
        "        df = pd.DataFrame([[name, accuracy*100, roc_auc, recall, precision, f1]], columns=cols)\n",
        "        data_table = data_table.append(df)\n",
        "\n",
        "    return(np.round(data_table.reset_index(drop=True), 2))\n",
        "\n",
        "\n",
        "def plot_conf_matrix(names, classifiers, nrows, ncols, fig_a, fig_b):\n",
        "    '''\n",
        "    Plots confusion matrices in a subplots.\n",
        "\n",
        "    Args:\n",
        "        names : list of names of the classifier\n",
        "        classifiers : list of classification algorithms\n",
        "        nrows, ncols : number of rows and rows in the subplots\n",
        "        fig_a, fig_b : dimensions of the figure size\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(fig_a, fig_b))\n",
        "\n",
        "    i = 0\n",
        "    for clf, ax in zip(classifiers, axes.flatten()):\n",
        "\n",
        "        clf.fit(X_train, y_train)\n",
        "        plot_confusion_matrix(clf, X_val, y_val, ax=ax)\n",
        "        ax.title.set_text(names[i])\n",
        "        i = i + 1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def roc_auc_curve(names, classifiers):\n",
        "    '''\n",
        "    Given a list of classifiers, this function plots the ROC curves\n",
        "\n",
        "    '''\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    for name, clf in zip(names, classifiers):\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        pred_proba = clf.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        fpr, tpr, thresholds = roc_curve(y_val, pred_proba)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, lw=3, label= name +' ROC curve (area = %0.2f)' % (roc_auc))\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.0])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver operating characteristic (ROC) curves', fontsize=20)\n",
        "        plt.legend(loc=\"lower right\")\n",
        ""
      ],
      "metadata": {
        "_kg_hide-input": true,
        "jupyter": {
          "source_hidden": true
        },
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:08.792245Z",
          "iopub.execute_input": "2023-04-30T16:24:08.792675Z",
          "iopub.status.idle": "2023-04-30T16:24:08.810374Z",
          "shell.execute_reply.started": "2023-04-30T16:24:08.792631Z",
          "shell.execute_reply": "2023-04-30T16:24:08.809327Z"
        },
        "trusted": true,
        "id": "Bn3jeuLWS-wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train and test sets\n",
        "\n",
        "cat_features = cat_feats\n",
        "data = label_encode_cat_features(data, cat_features)\n",
        "\n",
        "seed = 0\n",
        "test_size = 0.25\n",
        "\n",
        "features = data.columns[:-1]\n",
        "\n",
        "X = data[features]\n",
        "y = data['target']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = test_size, random_state=seed)\n",
        "\n",
        "\n",
        "# classifier algorithms with default parameters\n",
        "\n",
        "names = [\n",
        "    'Logistic Regression',\n",
        "    'Nearest Neighbors',\n",
        "    'Support Vectors',\n",
        "    'Nu SVC',\n",
        "    'Decision Tree',\n",
        "    'Random Forest',\n",
        "    'AdaBoost',\n",
        "    'Gradient Boosting',\n",
        "    'Naive Bayes',\n",
        "    'Linear DA',\n",
        "    'Quadratic DA',\n",
        "    \"Neural Net\"\n",
        "]\n",
        "\n",
        "classifiers = [\n",
        "    LogisticRegression(solver=\"liblinear\", random_state=seed),\n",
        "    KNeighborsClassifier(2),\n",
        "    SVC(probability=True, random_state=seed),\n",
        "    NuSVC(probability=True, random_state=seed),\n",
        "    DecisionTreeClassifier(random_state=seed),\n",
        "    RandomForestClassifier(random_state=seed),\n",
        "    AdaBoostClassifier(random_state=seed),\n",
        "    GradientBoostingClassifier(random_state=seed),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    MLPClassifier(random_state=seed),\n",
        "]\n"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "jupyter": {
          "source_hidden": true
        },
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:08.811807Z",
          "iopub.execute_input": "2023-04-30T16:24:08.812227Z",
          "iopub.status.idle": "2023-04-30T16:24:08.831092Z",
          "shell.execute_reply.started": "2023-04-30T16:24:08.812163Z",
          "shell.execute_reply": "2023-04-30T16:24:08.830065Z"
        },
        "trusted": true,
        "id": "V5BOqkeJS-wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1 Performance metric\n",
        "\n",
        "There are several metrics that can be used to gauge the performance of a given classification algorithm. The choice of the '*appropriate*' metrics is then dependent on the type of problem we are dealing with. There are case where, for example, *accuracy* can be the right choice and in some other case a *recall* or *precision* could be more fitting to the purpose. Since we are dealing with medical case (classify if a case is positive for heart disease or not), we could use recall (true positive rate or sensitivity) as performance metrics to choose our classifier. Note here that we do not want to classify positive (has disease) cases as negative (no disease).\n",
        "\n",
        "**Confusion matrix** : A confusion matrix (aka an error matrix) is a specific table layout that allows visualization of the performance of a supervised learning algorithm. Each row of the matrix represents the instances in an *actual* class while each column represents the instances in a *predicted* class [[wiki](https://en.wikipedia.org/wiki/Confusion_matrix)]. The table below is an example of a confusion matrix for a binary classification from which other terminologies/metric can be derived. Some of the metrics are described below.\n",
        "\n",
        "<div>    \n",
        "<img src=\"https://miro.medium.com/max/875/1*LQ1YMKBlbDhH9K6Ujz8QTw.jpeg\" width=\"350\", align=\"center\"/>  \n",
        "</div>\n",
        "\n",
        "[Image credit >>](https://towardsdatascience.com/demystifying-confusion-matrix-29f3037b0cfa)\n",
        "\n",
        "---\n",
        "\n",
        "**Key**:\n",
        "\n",
        "|**Term** |**Meaning** | **Descriptions**|\n",
        "| --- |---|---|\n",
        "|TP |True Positive|Positive cases which are predicted as positive|\n",
        "|FP |False Positive|Negative cases which are predicted as positive|\n",
        "|TN |True Negative|Negative cases which are predicted as negative|\n",
        "|FN |False Negative|Positive casea which are predicted as negative|\n",
        "\n",
        "---\n",
        "**Accuracy** : Measures how many of the cases are correctly identified/predicted by the model, i.e correct prediction divided by the total sample size.\n",
        "\n",
        "$\\frac{TP + TN}{TP +TN + FP + FN}$\n",
        "\n",
        "**Recall**: Measures the rate of *true positives*, i.e how many of the *actual* positive cases are *identified/predicted* as positive by the model.\n",
        "\n",
        "$\\frac{TP}{(TP + FN)}$\n",
        "\n",
        "**Precision**: Measures how many of the positive predicted cases are actually positive.\n",
        "\n",
        "$\\frac{TP}{(TP + FP)}$\n",
        "\n",
        "**F1-Score** : Combines the precision and recall of the model and it is defined as the harmonic mean of the model’s precision and recall.\n",
        "\n",
        "$2\\frac{recall * precision}{recall + precision}$\n",
        "\n",
        "**ROC curves** : A receiver operating characteristic (ROC) curve, is a graphical plot which illustrates the performance of a binary classification algorithm as a function of ture positive rate and false positive rate.\n",
        "\n",
        "<a href=\"#top\">☝️ Back to top</a>"
      ],
      "metadata": {
        "id": "S6WanaerS-wa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2 Performance metrics summary table"
      ],
      "metadata": {
        "id": "0pC93VgiS-wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_summary(names, classifiers).sort_values(by='Accuracy' , ascending = False)\\\n",
        ".style.background_gradient(cmap='coolwarm')\\\n",
        ".bar(subset=[\"ROC_AUC\",], color='#6495ED')\\\n",
        ".bar(subset=[\"Recall\"], color='#ff355d')\\\n",
        ".bar(subset=[\"Precision\"], color='lightseagreen')\\\n",
        ".bar(subset=[\"F1\"], color='gold')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:08.834859Z",
          "iopub.execute_input": "2023-04-30T16:24:08.835603Z",
          "iopub.status.idle": "2023-04-30T16:24:09.930586Z",
          "shell.execute_reply.started": "2023-04-30T16:24:08.835563Z",
          "shell.execute_reply": "2023-04-30T16:24:09.929643Z"
        },
        "trusted": true,
        "id": "9bSQ27DKS-wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.3 ROC curves"
      ],
      "metadata": {
        "id": "sPX0okFRS-wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_curve(names, classifiers)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:09.932133Z",
          "iopub.execute_input": "2023-04-30T16:24:09.932693Z",
          "iopub.status.idle": "2023-04-30T16:24:11.262408Z",
          "shell.execute_reply.started": "2023-04-30T16:24:09.93266Z",
          "shell.execute_reply": "2023-04-30T16:24:11.261605Z"
        },
        "trusted": true,
        "id": "k3SIX4X7S-wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.4 Confusion matrix"
      ],
      "metadata": {
        "id": "xzqX6XgQS-wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_conf_matrix(names, classifiers, nrows=4, ncols=3, fig_a=12, fig_b=12)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:11.263879Z",
          "iopub.execute_input": "2023-04-30T16:24:11.264384Z",
          "iopub.status.idle": "2023-04-30T16:24:14.140981Z",
          "shell.execute_reply.started": "2023-04-30T16:24:11.26435Z",
          "shell.execute_reply": "2023-04-30T16:24:14.139988Z"
        },
        "trusted": true,
        "id": "A60NvVy1S-wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have seen all the performance metrics of the classifiers, it is decision time for us to choose the best possible classifier algorithm. Based on precision LR ranks first (86%); whereas if we see the recall, Neural Nets ranks first with 94%. In the case of precision, QDA ranks first with 85%. So which one to choose? The F1-score can give us a balance between recall and precision. LR happens to have the best F1-score so we choose Logistic Regression as our best classifier.\n",
        "\n",
        "**Note**: If I were consulting a clinic doing a heart disease screening test, I would like to strike a perfect balance between precision and recall (I don't want the clinic to risk their reputation of by handing out too many false positive result but all without risking their clients' health by predicting too many false negatives). Therefore, I would advice them to choose the model which gives a higher F1-score, i.e the Logistic regression model."
      ],
      "metadata": {
        "id": "poQbf4OdS-wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.5 Parameter Tuning (RandomizedSearch): LogisticRegression\n",
        "\n",
        "So chosen our best classifier, the Logistic regression model. However, this was achieved with default parameters. The intuition is that we could further improve our model with tuned parameters. Let's see if could achieve that using the scikit-learn RandomizedSearch algorithm.  "
      ],
      "metadata": {
        "id": "G_fHggJpS-wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "\n",
        "lr = LogisticRegression(tol=1e-4, max_iter=1000, random_state=seed)\n",
        "\n",
        "space = dict(C=uniform(loc=0, scale=5),\n",
        "                     penalty=['l2', 'l1'],\n",
        "                     solver= ['liblinear'])\n",
        "\n",
        "search = RandomizedSearchCV(lr,\n",
        "                         space,\n",
        "                         random_state=seed,\n",
        "                         cv = 5,\n",
        "                         scoring='f1')\n",
        "\n",
        "rand_search = search.fit(X_train, y_train)\n",
        "\n",
        "print('Best Hyperparameters: %s' % rand_search.best_params_)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:14.142404Z",
          "iopub.execute_input": "2023-04-30T16:24:14.142916Z",
          "iopub.status.idle": "2023-04-30T16:24:14.73428Z",
          "shell.execute_reply.started": "2023-04-30T16:24:14.142856Z",
          "shell.execute_reply": "2023-04-30T16:24:14.733319Z"
        },
        "trusted": true,
        "id": "uZhVa39VS-wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = rand_search.best_params_\n",
        "lr = LogisticRegression(**params)\n",
        "lr.fit(X_train, y_train)\n",
        "print(classification_report(y_val, lr.predict(X_val)))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:14.735464Z",
          "iopub.execute_input": "2023-04-30T16:24:14.735774Z",
          "iopub.status.idle": "2023-04-30T16:24:14.752238Z",
          "shell.execute_reply.started": "2023-04-30T16:24:14.735737Z",
          "shell.execute_reply": "2023-04-30T16:24:14.751329Z"
        },
        "trusted": true,
        "id": "mF5VlSfCS-wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(lr, X_val, y_val)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:14.753539Z",
          "iopub.execute_input": "2023-04-30T16:24:14.754118Z",
          "iopub.status.idle": "2023-04-30T16:24:14.948968Z",
          "shell.execute_reply.started": "2023-04-30T16:24:14.754075Z",
          "shell.execute_reply": "2023-04-30T16:24:14.94766Z"
        },
        "trusted": true,
        "id": "LxJjjXA2S-wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark** : It turns out that our base model (default params) is not bad at all. Parameter tuning did not help to further increase the performance.\n",
        "\n",
        "<a href=\"#top\">☝️ Back to top</a>"
      ],
      "metadata": {
        "id": "_fBCsh1eS-wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 **Catboost, Lgbm and Xgboost** <a class=\"anchor\" id=\"2.2\"></a>\n",
        "\n",
        "In the above section (&&2.1) we have seen classifiers out of the scikit-learn library. Now we will try the modern (boosted trees) ML algorithms such as the [**catboost**](https://catboost.ai/), [**xgboost**](https://xgboost.readthedocs.io/en/stable/#) and [**lgbm**](https://lightgbm.readthedocs.io/en/latest/index.html). They are optimized machine learning algorithms based on the [**gradient-boosting**](https://en.wikipedia.org/wiki/Gradient_boosting) technique. Depending on the problem at hand, one algorithm is may be better suited than others. For detailed info one can easily refer to their documentations."
      ],
      "metadata": {
        "id": "yNgAl9ovS-we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "names_boost =[\n",
        "    'Catboost',\n",
        "    'xgbbost',\n",
        "    'light GBM'\n",
        "]\n",
        "classifiers = [\n",
        "    CatBoostClassifier(random_state=seed, verbose=0),\n",
        "    XGBClassifier(objective= 'binary:logistic', random_state=seed),\n",
        "    LGBMClassifier(random_state=seed)\n",
        "   ]"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:14.950912Z",
          "iopub.execute_input": "2023-04-30T16:24:14.951398Z",
          "iopub.status.idle": "2023-04-30T16:24:16.463308Z",
          "shell.execute_reply.started": "2023-04-30T16:24:14.951354Z",
          "shell.execute_reply": "2023-04-30T16:24:16.462294Z"
        },
        "trusted": true,
        "id": "GpdPip2TS-we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Performance metrics summary table"
      ],
      "metadata": {
        "id": "SFcCPEjXS-we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_summary(names_boost, classifiers).sort_values(by='Accuracy' , ascending = False)\\\n",
        ".style.background_gradient(cmap='coolwarm')\\\n",
        ".bar(subset=[\"ROC_AUC\",], color='#6495ED')\\\n",
        ".bar(subset=[\"Recall\"], color='#ff355d')\\\n",
        ".bar(subset=[\"Precision\"], color='lightseagreen')\\\n",
        ".bar(subset=[\"F1\"], color='gold')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:16.464671Z",
          "iopub.execute_input": "2023-04-30T16:24:16.464984Z",
          "iopub.status.idle": "2023-04-30T16:24:17.512641Z",
          "shell.execute_reply.started": "2023-04-30T16:24:16.464945Z",
          "shell.execute_reply": "2023-04-30T16:24:17.511549Z"
        },
        "trusted": true,
        "id": "9Q-o4c8ZS-we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 Confusion matrix"
      ],
      "metadata": {
        "id": "ZyW53vIpS-wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_conf_matrix(names=names_boost, classifiers=classifiers, nrows=1, ncols=3, fig_a=12, fig_b=3);"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:17.514323Z",
          "iopub.execute_input": "2023-04-30T16:24:17.515017Z",
          "iopub.status.idle": "2023-04-30T16:24:18.793984Z",
          "shell.execute_reply.started": "2023-04-30T16:24:17.514958Z",
          "shell.execute_reply": "2023-04-30T16:24:18.79145Z"
        },
        "trusted": true,
        "id": "q94SP_X_S-wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark** : Here we can see that the lgbm calssifier is marginally better than the other two and we will go for it. Following the same procedure, we will try to tune the parameters in the next section."
      ],
      "metadata": {
        "id": "nGbbvhlFS-wf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.3 Parameter Tuning (RandomizedSearch): LGBMClassifier"
      ],
      "metadata": {
        "id": "NsxKppYQS-wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "rs_params = {\n",
        "    'num_leaves': [20, 100],\n",
        "    'max_depth': [5, 15],\n",
        "    'min_data_in_leaf': [80, 120],\n",
        "}\n",
        "rs_cv = GridSearchCV(estimator=LGBMClassifier(random_state=seed, verbose=-1),\n",
        "                           param_grid=rs_params,\n",
        "                           cv = 5)\n",
        "\n",
        "rs_cv.fit(X_train, y_train)\n",
        "params = rs_cv.best_params_\n",
        "params"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:18.795704Z",
          "iopub.execute_input": "2023-04-30T16:24:18.796171Z",
          "iopub.status.idle": "2023-04-30T16:24:19.408525Z",
          "shell.execute_reply.started": "2023-04-30T16:24:18.796123Z",
          "shell.execute_reply": "2023-04-30T16:24:19.407575Z"
        },
        "trusted": true,
        "id": "XD117T7aS-wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm = LGBMClassifier(**params);\n",
        "\n",
        "lgbm.fit(X_train, y_train,\n",
        "        eval_set=(X_val, y_val),\n",
        "        verbose=False,\n",
        ");\n",
        "\n",
        "print(classification_report(y_val, lgbm.predict(X_val)))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:19.409863Z",
          "iopub.execute_input": "2023-04-30T16:24:19.410261Z",
          "iopub.status.idle": "2023-04-30T16:24:19.449596Z",
          "shell.execute_reply.started": "2023-04-30T16:24:19.410218Z",
          "shell.execute_reply": "2023-04-30T16:24:19.448529Z"
        },
        "trusted": true,
        "id": "alaCgo5ZS-wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(lgbm, X_val, y_val);"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:19.450791Z",
          "iopub.execute_input": "2023-04-30T16:24:19.45111Z",
          "iopub.status.idle": "2023-04-30T16:24:19.645962Z",
          "shell.execute_reply.started": "2023-04-30T16:24:19.451078Z",
          "shell.execute_reply": "2023-04-30T16:24:19.644856Z"
        },
        "trusted": true,
        "id": "xeF1hamSS-wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark**: In this case (Lgbm) hyper-parameter tuning gave better results than the base model. We have increased the recall value from 86% to 94%. Which means we have decrease the rate of false negatives from 5 cases to 2 in our validation set and we have also decreased the false positive cases by 1. Marginal but we will take every percentage point we can get.\n",
        "\n",
        "<a href=\"#top\">☝️ Back to top</a>"
      ],
      "metadata": {
        "id": "EeMRMwEgS-wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 **Model Explainablity** <a class=\"anchor\" id=\"2.3\"></a>\n",
        "\n",
        "One of the challenges of a machine leaning project is explaining the model's prediction. A model might consider some features more important than other for its prediction. Another model might weigh other features as more important. **Permutation importance** and **SHAP** are two methods one can use to understand which features were selected to have the most impact on our model's prediction.\n",
        "\n",
        "### 2.3.1 Permutation importance:\n",
        "The permutation importance is defined to be the **decrease in a model score** when a **single feature value** is *randomly shuffled*. The procedure breaks the relationship between the *feature* and the *target*, thus the drop in the **model score** is indicative of how much the model depends on the feature [[3](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)]. In other words, permutation importance tell us what features have the biggest impact on our model predictions."
      ],
      "metadata": {
        "id": "xLNQupH-S-wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "perm_imp = PermutationImportance(lgbm, random_state=seed).fit(X_train, y_train)\n",
        "eli5.show_weights(perm_imp, feature_names = X_val.columns.tolist())"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:19.647446Z",
          "iopub.execute_input": "2023-04-30T16:24:19.647856Z",
          "iopub.status.idle": "2023-04-30T16:24:19.985173Z",
          "shell.execute_reply.started": "2023-04-30T16:24:19.647813Z",
          "shell.execute_reply": "2023-04-30T16:24:19.98412Z"
        },
        "trusted": true,
        "id": "7ZZG2CYxS-wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2 SHAP:\n",
        "\n",
        "**SHAP**, a short name for **SH**apely **A**dditive Ex**P**lanations, is a method used to explain the output of a machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions [[5](https://shap.readthedocs.io/en/latest/index.html)]. SHAP has a rich functionality (methods) by which we can visualize/interpret the output of our models. Below we use the `shap.summary_plot()` to identify the impact each feature has on the predicted output.\n"
      ],
      "metadata": {
        "id": "dQBWy4xmS-wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "shap.initjs()\n",
        "explainer = shap.TreeExplainer(lgbm)\n",
        "shap_values = explainer.shap_values(X_val)\n",
        "shap.summary_plot(shap_values, X_val,\n",
        "                  feature_names=features,\n",
        "                  plot_type=\"bar\",\n",
        "                 )"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:19.986528Z",
          "iopub.execute_input": "2023-04-30T16:24:19.986848Z",
          "iopub.status.idle": "2023-04-30T16:24:20.311995Z",
          "shell.execute_reply.started": "2023-04-30T16:24:19.986813Z",
          "shell.execute_reply": "2023-04-30T16:24:20.311211Z"
        },
        "trusted": true,
        "id": "20OSRAONS-wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values[0], X_val)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-30T16:24:20.313366Z",
          "iopub.execute_input": "2023-04-30T16:24:20.313784Z",
          "iopub.status.idle": "2023-04-30T16:24:21.098886Z",
          "shell.execute_reply.started": "2023-04-30T16:24:20.31374Z",
          "shell.execute_reply": "2023-04-30T16:24:21.097988Z"
        },
        "trusted": true,
        "id": "Jp1uCf01S-wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 3. **Concluding Remark** <a class=\"anchor\" id=\"3\"></a>\n",
        "---\n",
        "At the start of this notebook, we laid out what we wanted to do with this project; to explore the heart disease dataset (EDA) and practice binary classification (modeling). In part one (EDA) we did explore the dataset, did a sanity check and removed some 'faulty' data and other pre-processing. We also tried to identify correlation between features and also with the target variable. In part two we practiced how to set-up binary classifiers; first starting with base models and finally arriving at our best model via hyper-parameter tuning. Some of the highlights are summarized below.\n",
        "\n",
        "- Our best model happens to be LGBM classifier (tuned with randomizedSearch)\n",
        "- According to both `eli5` permutation importance and `SHAP` the three most important features of the model are `num_major_vessels`, `chest_pain_type`, and `st_slope`. These features are also among better correlated features from our EDA.\n",
        "- Contrary to my intuition `cholesterol` happens to be not an important feature for the model (both eli5 and SHAP did not pick this feature as important).\n",
        "- Although it is not shown in this notebook, varying the test/train ratio resulted in different performance metrics for the classifiers we have on our list. So if you change the ratio you might get different results.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MQkRkLIpS-wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **Reference** <a class=\"anchor\" id=\"4\"></a>\n",
        "\n",
        "1. https://www.kaggle.com/tentotheminus9/what-causes-heart-disease-explaining-the-model\n",
        "2. https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9\n",
        "3. https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
        "4. https://www.kaggle.com/learn/machine-learning-explainability\n",
        "5. https://shap.readthedocs.io/en/latest/index.html\n",
        "6. https://www.healthline.com/health/serum-cholesterol#treatment\n",
        "7. https://www.who.int/news-room/fact-sheets/detail/cardiovascular-diseases-(cvds)\n",
        "8. https://www.indushealthplus.com/heart-diseases.html)"
      ],
      "metadata": {
        "id": "Mii6WS6kS-wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **End of Notebook!**\n",
        "\n",
        "<blockquote style=\"margin-right:auto; margin-left:auto; color:white; background-color: #4e4e4e; padding: 1em; margin:24px;\">\n",
        "\n",
        "<font color=\"white\" size=+1.0><b>Thank you for reading!</b></font>\n",
        "    \n",
        "<font color=\"white\" size=+1.0><b>If you have any feedback or comments please let me know.</b></font>\n",
        "    \n",
        "</blockquote>"
      ],
      "metadata": {
        "id": "JSiTnQqUS-wj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"#top\">☝️ Back to top</a>"
      ],
      "metadata": {
        "id": "D1kWhmuFS-wj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i605Hgr8S-wj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}